{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7967bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "# import shutil\n",
    "# import yaml\n",
    "# from pathlib import Path\n",
    "\n",
    "# def extract_and_merge_datasets(zip_path, output_dir=\"merged_dataset\"):\n",
    "\n",
    "#     # Create temporary directory for extraction\n",
    "#     temp_dir = \"temp_extract\"\n",
    "#     os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "#     # Create output directory structure\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     images_dir = os.path.join(output_dir, \"images\")\n",
    "#     labels_dir = os.path.join(output_dir, \"labels\")\n",
    "#     os.makedirs(images_dir, exist_ok=True)\n",
    "#     os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "#     # Extract the zip file\n",
    "#     print(f\"Extracting {zip_path} to {temp_dir}...\")\n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(temp_dir)\n",
    "\n",
    "#     # Look for data.yaml in the extracted files\n",
    "#     yaml_path = None\n",
    "#     class_names = []\n",
    "#     nc = 0\n",
    "\n",
    "#     for root, dirs, files in os.walk(temp_dir):\n",
    "#         for file in files:\n",
    "#             if file == \"data.yaml\":\n",
    "#                 yaml_path = os.path.join(root, file)\n",
    "#                 break\n",
    "\n",
    "#     # Read class information if data.yaml exists\n",
    "#     if yaml_path:\n",
    "#         with open(yaml_path, 'r') as f:\n",
    "#             yaml_data = yaml.safe_load(f)\n",
    "#             if 'names' in yaml_data:\n",
    "#                 class_names = yaml_data['names']\n",
    "#                 nc = len(class_names)\n",
    "#             elif 'classes' in yaml_data and isinstance(yaml_data['classes'], list):\n",
    "#                 class_names = yaml_data['classes']\n",
    "#                 nc = len(class_names)\n",
    "\n",
    "#     # Find and merge the train, val, test directories\n",
    "#     for split in ['train', 'valid', 'test']:\n",
    "#       split_dir = os.path.join(temp_dir, split)\n",
    "\n",
    "#       if os.path.exists(split_dir):\n",
    "#           print(f\"Processing {split} directory...\")\n",
    "\n",
    "#           # âœ… ë“¤ì—¬ì“°ê¸° í•˜ë‚˜ë§Œ (if ë¸”ë¡ ë‚´ë¶€)\n",
    "#           split_images_dir = os.path.join(split_dir, 'images')\n",
    "#           split_labels_dir = os.path.join(split_dir, 'labels')\n",
    "\n",
    "#           if os.path.exists(split_images_dir):\n",
    "#               for img in os.listdir(split_images_dir):\n",
    "#                   src = os.path.join(split_images_dir, img)\n",
    "#                   dst = os.path.join(images_dir, img)\n",
    "#                   os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "#                   shutil.copy2(src, dst)\n",
    "\n",
    "#           if os.path.exists(split_labels_dir):\n",
    "#               for ann in os.listdir(split_labels_dir):\n",
    "#                   src = os.path.join(split_labels_dir, ann)\n",
    "#                   dst = os.path.join(labels_dir, ann)\n",
    "#                   os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "#                   shutil.copy2(src, dst)\n",
    "\n",
    "#     # Create new data.yaml file\n",
    "#     img_count = len(os.listdir(images_dir))\n",
    "#     label_count = len(os.listdir(labels_dir))\n",
    "\n",
    "#     # Determine path to dataset\n",
    "#     dataset_path = os.path.abspath(output_dir)\n",
    "\n",
    "#     # Create new data.yaml\n",
    "#     data_yaml = {\n",
    "#         'path': dataset_path,\n",
    "#         'train': 'images',\n",
    "#         'val': 'images',\n",
    "#         'test': 'images',\n",
    "#         'nc': nc,\n",
    "#         'names': class_names\n",
    "#     }\n",
    "\n",
    "#     yaml_out_path = os.path.join(output_dir, 'data.yaml')\n",
    "#     with open(yaml_out_path, 'w') as f:\n",
    "#         yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "#     # Clean up temporary directory\n",
    "#     print(f\"Cleaning up temporary files...\")\n",
    "#     shutil.rmtree(temp_dir)\n",
    "\n",
    "#     print(f\"Successfully merged datasets into {output_dir}\")\n",
    "#     print(f\"Total images: {img_count}\")\n",
    "#     print(f\"Total labels: {label_count}\")\n",
    "#     print(f\"Created data.yaml with {nc} classes\")\n",
    "#     if nc > 0:\n",
    "#         print(f\"Classes: {', '.join(class_names)}\")\n",
    "#     else:\n",
    "#         print(\"Warning: No class information found in original data.yaml\")\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6665f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_files= ['/content/drive/MyDrive/CV2/Datasets/final-airplane--1.zip']\n",
    "# for zip_path in zip_files:\n",
    "#     output_dir = zip_path.split('.')[0]\n",
    "#     print(f\"Processing {zip_path} -> {output_dir}\")\n",
    "#     print(\"=\"*50)\n",
    "#     extract_and_merge_datasets(zip_path, output_dir)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef03e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# import yaml\n",
    "# from glob import glob\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# def create_random_splits(data_dir, n_splits=5, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "#     \"\"\"\n",
    "#     ë‹¨ì¼ ë°ì´í„° ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ì™€ ë¼ë²¨ ë°ì´í„°ì…‹ì„ Nê°œì˜ ëœë¤ train/val/testë¡œ ë¶„í• í•˜ê³  ê´€ë ¨ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. #ì™œëƒë©´ í•œê°œë¡œ í•©ì³ì„œ\n",
    "\n",
    "#     Args:\n",
    "#         data_dir (str): ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (images, labels í´ë”ì™€ data.yaml íŒŒì¼ì„ í¬í•¨)\n",
    "#         n_splits (int): ìƒì„±í•  ë°ì´í„°ì…‹ ë¶„í•  ìˆ˜\n",
    "#         train_ratio (float): í•™ìŠµ ë°ì´í„° ë¹„ìœ¨\n",
    "#         val_ratio (float): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨\n",
    "#         test_ratio (float): í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨\n",
    "#     \"\"\"\n",
    "#     # ë¹„ìœ¨ í•©ì´ 1ì¸ì§€ í™•ì¸\n",
    "#     assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-10, \"ë¹„ìœ¨ì˜ í•©ì€ 1ì´ì–´ì•¼ í•©ë‹ˆë‹¤\" #assertì œëŒ€ë¡œ ì•ˆì“°ë©´ errorë°°ì¶œ trueì¼ë•ŒëŠ” ë„˜ì–´ê°\n",
    "\n",
    "#     # ê²½ë¡œ ì„¤ì •\n",
    "#     images_dir = os.path.join(data_dir, 'images')\n",
    "#     labels_dir = os.path.join(data_dir, 'labels')\n",
    "#     yaml_path = os.path.join(data_dir, 'data.yaml')\n",
    "\n",
    "#     # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸\n",
    "#     if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "#         print(f\"ê²½ê³ : {data_dir}ì— images ë˜ëŠ” labels í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "#         return\n",
    "\n",
    "#     # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (í™•ì¥ìëŠ” í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)\n",
    "#     image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "#     image_files = []\n",
    "#     for ext in image_extensions:\n",
    "#         image_files.extend(glob(os.path.join(images_dir, ext))) #glob() í•¨ìˆ˜ëŠ” ì¸ìë¡œ ë°›ì€ íŒ¨í„´ê³¼ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ëª¨ë“  íŒŒì¼ê³¼ ë””ë ‰í„°ë¦¬ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜\n",
    "#     #ì¦‰ ì €ê¸°ì— ìˆëŠ” í™•ì¥ìë“¤ì€ ë‹¤ returní•´ì¤€ë‹¤ê³  ìƒê°í•˜ë©´ë©´ë¨ë¨\n",
    "#     # ì´ë¯¸ì§€ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ (í™•ì¥ì í¬í•¨)\n",
    "#     image_filenames = [os.path.basename(f) for f in image_files] #ìê¸° ìœ„ì¹˜ í´ë”ë©´ í´ë”ëª…ëª… íŒŒì¼ì´ë©´ íŒŒì¼ëª… ë°˜í™˜í™˜\n",
    "\n",
    "#     # í•´ë‹¹ ì´ë¯¸ì§€ íŒŒì¼ì— ëŒ€ì‘í•˜ëŠ” ë¼ë²¨ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "#     valid_samples = []\n",
    "#     for img_filename in image_filenames:\n",
    "#         # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ê³  ë¼ë²¨ íŒŒì¼ í™•ì¥ì ì¶”ê°€\n",
    "#         base_name = os.path.splitext(img_filename)[0]\n",
    "#         label_path = os.path.join(labels_dir, base_name + '.txt')\n",
    "\n",
    "#         # ë¼ë²¨ íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ìœ íš¨í•œ ìƒ˜í”Œë¡œ ê°„ì£¼\n",
    "#         if os.path.exists(label_path):\n",
    "#             valid_samples.append((img_filename, base_name + '.txt')) #ì¼ë‹¨ ë¼ë²¨ì„ ë‹¤ ë§Œë“¤ì—ˆëŠ”ë° ìˆìœ¼ë©´ ì´ê²Œ ì‹¤í–‰ì´ë¨ ê·¸ë˜ì„œ ì´ë¯¸ì§€ë‘ ë¼ë²¨ì´ ë‘˜ë‹¤ ìˆìœ¼ë‹ˆê¹Œ valid sampleì— ì¶”ê°€ê°€\n",
    "\n",
    "#     if not valid_samples:\n",
    "#         print(f\"ì˜¤ë¥˜: {data_dir}ì—ì„œ ìœ íš¨í•œ ìƒ˜í”Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "#         return\n",
    "#     #ì—¬ê¸°ê¹Œì§€ ê³µë¶€ë¶€\n",
    "\n",
    "#     # data.yaml íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "#     try:\n",
    "#         with open(yaml_path, 'r') as f:\n",
    "#             data_yaml = yaml.safe_load(f)\n",
    "#             nc = data_yaml.get('nc', 0)\n",
    "#             names = data_yaml.get('names', [])\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"ê²½ê³ : {yaml_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ncì™€ namesëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\")\n",
    "#         nc = 0\n",
    "#         names = []\n",
    "\n",
    "#     print(f\"{data_dir}: {len(valid_samples)}ê°œì˜ ìœ íš¨í•œ ìƒ˜í”Œì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "#     # Nê°œì˜ ëœë¤ ë¶„í•  ìƒì„±\n",
    "#     for iter_idx in range(1, n_splits + 1):\n",
    "#         # ë°ì´í„° ì„¸íŠ¸ ë¶„í• \n",
    "#         random.shuffle(valid_samples) #ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” random sampleì„ ì•Œì•„ì„œ ë‚˜ëˆ”\n",
    "\n",
    "\n",
    "#         # ë¨¼ì € trainê³¼ temp(val+test) ë¶„í• \n",
    "#         train_samples, temp_samples = train_test_split(\n",
    "#             valid_samples,\n",
    "#             train_size=train_ratio,\n",
    "#             test_size=val_ratio + test_ratio,\n",
    "#             random_state=42 + iter_idx  # ê° ë°˜ë³µë§ˆë‹¤ ë‹¤ë¥¸ ì‹œë“œ ì‚¬ìš©\n",
    "#         )\n",
    "\n",
    "#         # tempë¥¼ valê³¼ testë¡œ ë¶„í• \n",
    "#         val_ratio_adjusted = val_ratio / (val_ratio + test_ratio)\n",
    "#         val_samples, test_samples = train_test_split(\n",
    "#             temp_samples,\n",
    "#             train_size=val_ratio_adjusted,\n",
    "#             test_size=1 - val_ratio_adjusted,\n",
    "#             random_state=42 + iter_idx\n",
    "#         )\n",
    "\n",
    "#         # í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±\n",
    "#         train_txt_path = os.path.join(data_dir, f'train_iter_{iter_idx:02d}.txt')\n",
    "#         val_txt_path = os.path.join(data_dir, f'val_iter_{iter_idx:02d}.txt')\n",
    "#         test_txt_path = os.path.join(data_dir, f'test_iter_{iter_idx:02d}.txt')\n",
    "\n",
    "#         # í•™ìŠµ ë°ì´í„° íŒŒì¼ ì“°ê¸°\n",
    "#         with open(train_txt_path, 'w') as f:\n",
    "#             for img_file, _ in train_samples:\n",
    "#                 img_path = os.path.join('images', img_file)  # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#                 f.write(f\"{img_path}\\n\")\n",
    "\n",
    "#         # ê²€ì¦ ë°ì´í„° íŒŒì¼ ì“°ê¸°\n",
    "#         with open(val_txt_path, 'w') as f:\n",
    "#             for img_file, _ in val_samples:\n",
    "#                 img_path = os.path.join('images', img_file)  # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#                 f.write(f\"{img_path}\\n\")\n",
    "\n",
    "#         # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ì“°ê¸°\n",
    "#         with open(test_txt_path, 'w') as f:\n",
    "#             for img_file, _ in test_samples:\n",
    "#                 img_path = os.path.join('images', img_file)  # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#                 f.write(f\"{img_path}\\n\")\n",
    "\n",
    "#         # YAML íŒŒì¼ ìƒì„±\n",
    "#         output_yaml_path = os.path.join(data_dir, f'data_iter_{iter_idx:02d}.yaml')\n",
    "#         yaml_content = {\n",
    "#             'train': f'train_iter_{iter_idx:02d}.txt',  # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#             'val': f'val_iter_{iter_idx:02d}.txt',      # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#             'test': f'test_iter_{iter_idx:02d}.txt',    # ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©\n",
    "#             'nc': nc,\n",
    "#             'names': names\n",
    "#         }\n",
    "\n",
    "#         with open(output_yaml_path, 'w') as f:\n",
    "#             yaml.dump(yaml_content, f, default_flow_style=False)\n",
    "\n",
    "#         print(f\"{data_dir} - Iteration {iter_idx} ì™„ë£Œ: {len(train_samples)} í•™ìŠµ, {len(val_samples)} ê²€ì¦, {len(test_samples)} í…ŒìŠ¤íŠ¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34ca3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dirs = ['/content/drive/MyDrive/CV2/Datasets/final-airplane--1']\n",
    "# n_splits = 10\n",
    "# train_ratio = 0.6\n",
    "# val_ratio = 0.2\n",
    "# test_ratio = 0.2\n",
    "\n",
    "# for data_dir in data_dirs:\n",
    "#         print(f\"\\nì²˜ë¦¬ ì¤‘: {data_dir}\")\n",
    "#         create_random_splits(data_dir, n_splits, train_ratio, val_ratio, test_ratio) #ì—¬ê¸°ê¹Œì§€ dataì „ì²˜ì§€ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bb8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import albumentations as A\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # ì„¤ì •\n",
    "# txt_base_dir = '/content/drive/MyDrive/01/Datasets/final-airplane--1' #ë¡œì»¬ì— ë§ì¶°ì„œ ê°œì„ \n",
    "# input_img_dir = os.path.join(txt_base_dir, 'images')\n",
    "# input_lbl_dir = os.path.join(txt_base_dir, 'labels')\n",
    "# output_img_dir = input_img_dir\n",
    "# output_lbl_dir = input_lbl_dir\n",
    "\n",
    "# # ì¦ê°• ì •ì˜\n",
    "# transform = A.Compose([\n",
    "#     A.RandomSizedCrop(min_max_height=(300, 500), size=(640, 640), p=0.3),\n",
    "#     A.Rotate(limit=30, p=0.4),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.HueSaturationValue(p=0.4),\n",
    "#     A.RGBShift(p=0.3),\n",
    "#     A.RandomBrightnessContrast(brightness_limit=(-0.4, 0.1), contrast_limit=0.3, p=0.4),\n",
    "#     A.Resize(height=640, width=640, p=1.0),\n",
    "#     A.GaussianBlur(p=0.1)\n",
    "# ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels'], min_visibility=0.3))\n",
    "\n",
    "\n",
    "# # train_iter_01 ~ train_iter_10\n",
    "# for i in range(1, 11):\n",
    "#     iter_id = f\"{i:02d}\"\n",
    "#     txt_name = f\"train_iter_{iter_id}.txt\"\n",
    "#     txt_path = os.path.join(txt_base_dir, txt_name)\n",
    "\n",
    "#     if not os.path.exists(txt_path):\n",
    "#         print(f\"âŒ {txt_name} ì—†ìŒ - ê±´ë„ˆëœ€\")\n",
    "#         continue\n",
    "\n",
    "#     with open(txt_path, 'r') as f:\n",
    "#         image_paths = [line.strip() for line in f.readlines()]\n",
    "\n",
    "#     print(f\"ğŸ”„ {txt_name} ì²˜ë¦¬ ì¤‘ ({len(image_paths)}ì¥)\")\n",
    "\n",
    "#     new_lines = []\n",
    "\n",
    "#     for img_path in tqdm(image_paths):\n",
    "#         img_name = os.path.basename(img_path)\n",
    "#         img_stem = os.path.splitext(img_name)[0]\n",
    "#         input_img_path = os.path.join(input_img_dir, img_name)\n",
    "#         input_lbl_path = os.path.join(input_lbl_dir, f\"{img_stem}.txt\")\n",
    "\n",
    "#         image = cv2.imread(input_img_path)\n",
    "#         if image is None:\n",
    "#             print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {input_img_path}\")\n",
    "#             continue\n",
    "\n",
    "#         # ë¼ë²¨ ë¡œë“œ\n",
    "#         bboxes = []\n",
    "#         class_labels = []\n",
    "#         if os.path.exists(input_lbl_path):\n",
    "#             with open(input_lbl_path, 'r') as f:\n",
    "#                 for line in f:\n",
    "#                     parts = line.strip().split()\n",
    "#                     if len(parts) == 5:\n",
    "#                         cls, x, y, w, h = parts\n",
    "#                         bboxes.append([float(x), float(y), float(w), float(h)])\n",
    "#                         class_labels.append(int(cls))\n",
    "\n",
    "#         try:\n",
    "#             transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "#         except Exception as e:\n",
    "#             print(f\"âš ï¸ bbox ì˜¤ë¥˜ë¡œ í•´ë‹¹ ì´ë¯¸ì§€ ê±´ë„ˆëœ€: {img_path}\")\n",
    "#             continue\n",
    "\n",
    "#         aug_image = transformed['image']\n",
    "#         aug_bboxes = transformed['bboxes']\n",
    "#         aug_labels = transformed['class_labels']\n",
    "\n",
    "#         if not aug_bboxes:\n",
    "#             continue\n",
    "\n",
    "#         # ì €ì¥ íŒŒì¼ëª…\n",
    "#         aug_img_name = f\"aug_{img_name}\"\n",
    "#         aug_lbl_name = f\"aug_{img_stem}.txt\"\n",
    "#         save_img_path = os.path.join(output_img_dir, aug_img_name)\n",
    "#         save_lbl_path = os.path.join(output_lbl_dir, aug_lbl_name)\n",
    "\n",
    "#         # ì €ì¥\n",
    "#         cv2.imwrite(save_img_path, aug_image)\n",
    "#         with open(save_lbl_path, 'w') as f:\n",
    "#             for bbox, cls in zip(aug_bboxes, aug_labels):\n",
    "#                 f.write(f\"{cls} {' '.join(f'{x:.6f}' for x in bbox)}\\n\")\n",
    "\n",
    "#         # txtì— ê¸°ë¡í•  ìƒˆë¡œìš´ ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "#         new_lines.append(save_img_path)\n",
    "\n",
    "#     # ê¸°ì¡´ train_iter_xx.txtì— ë§ë¶™ì´ê¸°\n",
    "#     with open(txt_path, 'a') as f:\n",
    "#         for new_line in new_lines:\n",
    "#             f.write(f\"{new_line}\\n\")\n",
    "\n",
    "#     print(f\"âœ… {txt_name} ì— ì¦ê°• ì´ë¯¸ì§€ {len(new_lines)}ì¥ ì¶”ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# print(\"ğŸ‰ ì „ì²´ train_iter_xx íŒŒì¼ì— ì¦ê°• ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€ ì™„ë£Œ\")\n",
    "#ì´ê±´ ì „ì²´ê³¼ì • í•œë²ˆì— ë‹¤í•œê±°ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a22a04-1665-4ea8-b1a4-e0172ce1a30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CBAM registered: True\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8_1n.yaml, data=Datasets/Crown Detection/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=tmp, name=250423_112117_yolov8n_Crown Detection_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.0001, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250423_112117_yolov8n_Crown Detection_Iter_1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       696  ultralytics.nn.modules.conv.Conv             [3, 24, 3, 2]                 \n",
      "  1                  -1  1      8720  ultralytics.nn.modules.conv.Conv             [24, 40, 3, 2]                \n",
      "  2                  -1  1       258  models.common.CBAM                           [40]                          \n",
      "  3                  -1  1     11440  ultralytics.nn.modules.block.C2f             [40, 40, 1, True]             \n",
      "  4                  -1  1     28960  ultralytics.nn.modules.conv.Conv             [40, 80, 3, 2]                \n",
      "  5                  -1  1       898  models.common.CBAM                           [80]                          \n",
      "  6                  -1  2     77440  ultralytics.nn.modules.block.C2f             [80, 80, 2, True]             \n",
      "  7                  -1  1    109744  ultralytics.nn.modules.conv.Conv             [80, 152, 3, 2]               \n",
      "  8                  -1  2    278464  ultralytics.nn.modules.block.C2f             [152, 152, 2, True]           \n",
      "  9                  -1  1    405520  ultralytics.nn.modules.conv.Conv             [152, 296, 3, 2]              \n",
      " 10                  -1  1     10754  models.common.CBAM                           [296]                         \n",
      " 11                  -1  1    615088  ultralytics.nn.modules.block.C2f             [296, 296, 1, True]           \n",
      " 12                  -1  1    219928  ultralytics.nn.modules.block.SPPF            [296, 296, 5]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    207632  ultralytics.nn.modules.block.C2f             [448, 152, 1]                 \n",
      " 16                  -1  1      2834  models.common.CBAM                           [152]                         \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     57440  ultralytics.nn.modules.block.C2f             [232, 80, 1]                  \n",
      " 20                  -1  1       898  models.common.CBAM                           [80]                          \n",
      " 21                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 22             [-1, 3]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1     14640  ultralytics.nn.modules.block.C2f             [120, 40, 1]                  \n",
      " 24                  -1  1     14480  ultralytics.nn.modules.conv.Conv             [40, 40, 3, 2]                \n",
      " 25            [-1, 20]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 26                  -1  1     48480  ultralytics.nn.modules.block.C2f             [120, 80, 1]                  \n",
      " 27                  -1  1     57760  ultralytics.nn.modules.conv.Conv             [80, 80, 3, 2]                \n",
      " 28            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 29                  -1  1    174800  ultralytics.nn.modules.block.C2f             [232, 152, 1]                 \n",
      " 30                  -1  1    208240  ultralytics.nn.modules.conv.Conv             [152, 152, 3, 2]              \n",
      " 31            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 32                  -1  1    660080  ultralytics.nn.modules.block.C2f             [448, 296, 1]                 \n",
      " 33    [23, 26, 29, 32]  1    755188  ultralytics.nn.modules.head.Detect           [1, [40, 80, 152, 296]]       \n",
      "YOLOv8_1n summary: 195 layers, 3,970,382 parameters, 3,970,366 gradients, 16.7 GFLOPs\n",
      "\n",
      "Freezing layer 'model.33.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Crown Detection\\labels... 348 images, 68 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 1844.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Crown Detection\\labels... 116 images, 27 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 1738.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp\\250423_112117_yolov8n_Crown Detection_Iter_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.0001) with parameter groups 70 weight(decay=0.0), 94 weight(decay=0.0001), 78 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250423_112117_yolov8n_Crown Detection_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      3.098      3.436      3.486         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:19<00:00,  9.08s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00196     0.0549    0.00608    0.00385\n",
      "\n",
      "1 epochs completed in 0.064 hours.\n",
      "Optimizer stripped from tmp\\250423_112117_yolov8n_Crown Detection_Iter_1\\weights\\last.pt, 8.4MB\n",
      "Optimizer stripped from tmp\\250423_112117_yolov8n_Crown Detection_Iter_1\\weights\\best.pt, 8.4MB\n",
      "\n",
      "Validating tmp\\250423_112117_yolov8n_Crown Detection_Iter_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "YOLOv8_1n summary (fused): 125 layers, 3,963,906 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00192     0.0524    0.00207    0.00105\n",
      "Speed: 2.7ms preprocess, 168.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mtmp\\250423_112117_yolov8n_Crown Detection_Iter_1\u001b[0m\n",
      "Transferred 452/452 items from pretrained weights\n",
      "ê²°ê³¼ê°€ 250423_112117_submission_1_20214173_Iter_1_detection_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov11n.yaml, data=Datasets/Crown Detection/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=tmp, name=250423_112553_yolov11n_Crown Detection_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.0001, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250423_112553_yolov11n_Crown Detection_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Crown Detection\\labels... 348 images, 68 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 1982.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Crown Detection\\labels... 116 images, 27 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 1747.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n",
      "Plotting labels to tmp\\250423_112553_yolov11n_Crown Detection_Iter_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.0001) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250423_112553_yolov11n_Crown Detection_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      3.594      3.104      3.436         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [01:39<00:00,  4.54s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:10<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00243     0.0677    0.00198   0.000807\n",
      "\n",
      "1 epochs completed in 0.031 hours.\n",
      "Optimizer stripped from tmp\\250423_112553_yolov11n_Crown Detection_Iter_1\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from tmp\\250423_112553_yolov11n_Crown Detection_Iter_1\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating tmp\\250423_112553_yolov11n_Crown Detection_Iter_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "YOLOv11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00248      0.069    0.00339    0.00149\n",
      "Speed: 0.7ms preprocess, 67.6ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mtmp\\250423_112553_yolov11n_Crown Detection_Iter_1\u001b[0m\n",
      "ê²°ê³¼ê°€ 250423_112553_submission_2_20214173_Iter_1_detection_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov12n.yaml, data=Datasets/Crown Detection/data_iter_01.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=tmp, name=250423_112810_yolov12n_Crown Detection_Iter_1, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.0001, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250423_112810_yolov12n_Crown Detection_Iter_1\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  2    180864  ultralytics.nn.modules.block.A2C2f           [128, 128, 2, True, 4]        \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  2    689408  ultralytics.nn.modules.block.A2C2f           [256, 256, 2, True, 1]        \n",
      "  9                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 10             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 11                  -1  1     86912  ultralytics.nn.modules.block.A2C2f           [384, 128, 1, False, -1]      \n",
      " 12                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 13             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 14                  -1  1     24000  ultralytics.nn.modules.block.A2C2f           [256, 64, 1, False, -1]       \n",
      " 15                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 16            [-1, 11]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     74624  ultralytics.nn.modules.block.A2C2f           [192, 128, 1, False, -1]      \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 21        [14, 17, 20]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv12n summary: 272 layers, 2,568,243 parameters, 2,568,227 gradients, 6.5 GFLOPs\n",
      "\n",
      "Freezing layer 'model.21.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Crown Detection\\labels... 348 images, 68 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 2063.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Crown Detection\\labels... 116 images, 27 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 1886.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n",
      "Plotting labels to tmp\\250423_112810_yolov12n_Crown Detection_Iter_1\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.0001) with parameter groups 113 weight(decay=0.0), 120 weight(decay=0.0001), 119 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250423_112810_yolov12n_Crown Detection_Iter_1\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      3.641      3.347      3.511         92        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [01:50<00:00,  5.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00391      0.174     0.0034    0.00122\n",
      "\n",
      "1 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from tmp\\250423_112810_yolov12n_Crown Detection_Iter_1\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from tmp\\250423_112810_yolov12n_Crown Detection_Iter_1\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating tmp\\250423_112810_yolov12n_Crown Detection_Iter_1\\weights\\best.pt...\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "YOLOv12n summary (fused): 159 layers, 2,556,923 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:17<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        783    0.00405       0.18    0.00443    0.00153\n",
      "Speed: 0.8ms preprocess, 76.5ms inference, 0.0ms loss, 67.2ms postprocess per image\n",
      "Results saved to \u001b[1mtmp\\250423_112810_yolov12n_Crown Detection_Iter_1\u001b[0m\n",
      "ê²°ê³¼ê°€ 250423_112810_submission_3_20214173_Iter_1_detection_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "âœ… CBAM registered: True\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8_1n.yaml, data=Datasets/Crown Detection/data_iter_02.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=tmp, name=250423_113057_yolov8n_Crown Detection_Iter_2, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.0001, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250423_113057_yolov8n_Crown Detection_Iter_2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       696  ultralytics.nn.modules.conv.Conv             [3, 24, 3, 2]                 \n",
      "  1                  -1  1      8720  ultralytics.nn.modules.conv.Conv             [24, 40, 3, 2]                \n",
      "  2                  -1  1       258  models.common.CBAM                           [40]                          \n",
      "  3                  -1  1     11440  ultralytics.nn.modules.block.C2f             [40, 40, 1, True]             \n",
      "  4                  -1  1     28960  ultralytics.nn.modules.conv.Conv             [40, 80, 3, 2]                \n",
      "  5                  -1  1       898  models.common.CBAM                           [80]                          \n",
      "  6                  -1  2     77440  ultralytics.nn.modules.block.C2f             [80, 80, 2, True]             \n",
      "  7                  -1  1    109744  ultralytics.nn.modules.conv.Conv             [80, 152, 3, 2]               \n",
      "  8                  -1  2    278464  ultralytics.nn.modules.block.C2f             [152, 152, 2, True]           \n",
      "  9                  -1  1    405520  ultralytics.nn.modules.conv.Conv             [152, 296, 3, 2]              \n",
      " 10                  -1  1     10754  models.common.CBAM                           [296]                         \n",
      " 11                  -1  1    615088  ultralytics.nn.modules.block.C2f             [296, 296, 1, True]           \n",
      " 12                  -1  1    219928  ultralytics.nn.modules.block.SPPF            [296, 296, 5]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 8]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    207632  ultralytics.nn.modules.block.C2f             [448, 152, 1]                 \n",
      " 16                  -1  1      2834  models.common.CBAM                           [152]                         \n",
      " 17                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 18             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     57440  ultralytics.nn.modules.block.C2f             [232, 80, 1]                  \n",
      " 20                  -1  1       898  models.common.CBAM                           [80]                          \n",
      " 21                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 22             [-1, 3]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1     14640  ultralytics.nn.modules.block.C2f             [120, 40, 1]                  \n",
      " 24                  -1  1     14480  ultralytics.nn.modules.conv.Conv             [40, 40, 3, 2]                \n",
      " 25            [-1, 20]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 26                  -1  1     48480  ultralytics.nn.modules.block.C2f             [120, 80, 1]                  \n",
      " 27                  -1  1     57760  ultralytics.nn.modules.conv.Conv             [80, 80, 3, 2]                \n",
      " 28            [-1, 16]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 29                  -1  1    174800  ultralytics.nn.modules.block.C2f             [232, 152, 1]                 \n",
      " 30                  -1  1    208240  ultralytics.nn.modules.conv.Conv             [152, 152, 3, 2]              \n",
      " 31            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 32                  -1  1    660080  ultralytics.nn.modules.block.C2f             [448, 296, 1]                 \n",
      " 33    [23, 26, 29, 32]  1    755188  ultralytics.nn.modules.head.Detect           [1, [40, 80, 152, 296]]       \n",
      "YOLOv8_1n summary: 195 layers, 3,970,382 parameters, 3,970,366 gradients, 16.7 GFLOPs\n",
      "\n",
      "Freezing layer 'model.33.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Crown Detection\\labels... 348 images, 69 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 1920.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Crown Detection\\labels... 116 images, 24 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 2367.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tmp\\250423_113057_yolov8n_Crown Detection_Iter_2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.0001) with parameter groups 70 weight(decay=0.0), 94 weight(decay=0.0001), 78 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250423_113057_yolov8n_Crown Detection_Iter_2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      3.077      3.426      3.492        133        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [03:38<00:00,  9.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:49<00:00, 12.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        730    0.00212      0.074    0.00136   0.000559\n",
      "\n",
      "1 epochs completed in 0.075 hours.\n",
      "Optimizer stripped from tmp\\250423_113057_yolov8n_Crown Detection_Iter_2\\weights\\last.pt, 8.4MB\n",
      "Optimizer stripped from tmp\\250423_113057_yolov8n_Crown Detection_Iter_2\\weights\\best.pt, 8.4MB\n",
      "\n",
      "Validating tmp\\250423_113057_yolov8n_Crown Detection_Iter_2\\weights\\best.pt...\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "YOLOv8_1n summary (fused): 125 layers, 3,963,906 parameters, 0 gradients, 16.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:36<00:00,  9.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        116        730    0.00212      0.074    0.00201   0.000681\n",
      "Speed: 4.5ms preprocess, 287.0ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
      "Results saved to \u001b[1mtmp\\250423_113057_yolov8n_Crown Detection_Iter_2\u001b[0m\n",
      "Transferred 452/452 items from pretrained weights\n",
      "ê²°ê³¼ê°€ 250423_113057_submission_1_20214173_Iter_2_detection_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "New https://pypi.org/project/ultralytics/8.3.114 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.96  Python-3.10.16 torch-2.6.0+cpu CPU (13th Gen Intel Core(TM) i5-1335U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov11n.yaml, data=Datasets/Crown Detection/data_iter_02.yaml, epochs=1, time=None, patience=20, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=tmp, name=250423_113643_yolov11n_Crown Detection_Iter_2, exist_ok=True, pretrained=False, optimizer=AdamW, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=False, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.0001, weight_decay=0.0001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=tmp\\250423_113643_yolov11n_Crown Detection_Iter_2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning Datasets\\Crown Detection\\labels... 348 images, 69 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:00<00:00, 2171.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning Datasets\\Crown Detection\\labels... 116 images, 24 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 2150.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: Datasets\\Crown Detection\\labels.cache\n",
      "Plotting labels to tmp\\250423_113643_yolov11n_Crown Detection_Iter_2\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.0001) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mtmp\\250423_113643_yolov11n_Crown Detection_Iter_2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1         0G      3.626       3.23      3.562        122        640:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 17/22 [01:52<00:24,  4.95s/it]"
     ]
    }
   ],
   "source": [
    "from competition_utils import *\n",
    "# submission_1_20214173.py ìƒë‹¨ì— ì¶”ê°€!\n",
    "from models.common import CBAM  # common.pyì— ì •ì˜í•œ CBAM ê²½ë¡œ\n",
    "\n",
    "# ë“±ë¡: YAMLì—ì„œ 'CBAM'ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆë„ë¡ ì—°ê²°\n",
    "import ultralytics.nn.modules as modules\n",
    "modules.CBAM = CBAM\n",
    "\n",
    "# ì œì¶œ í•¨ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜ (submission_N_í•™ë²ˆ)\n",
    "# ê¹ƒí—ˆë¸Œì—ëŠ” ìµœëŒ€ 3ê°œ ì—…ë¡œë“œ ë°ëª¨ì‹œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ í›„ 1ê°œë§Œ ì œì¶œ\n",
    "submission_functions = ['submission_1_20214173', 'submission_2_20214173', 'submission_3_20214173']  \n",
    "for submission_function in submission_functions:\n",
    "    exec(f\"from {submission_function} import {submission_function}\")\n",
    "\n",
    "# ë¶„ì„ ë°©í–¥ì— ë”°ë¼ iteration ìˆ˜ ìˆ˜ì •\n",
    "# í‰ê°€ì‹œì—ëŠ” ë°ëª¨ì™€ ë‹¤ë¥¸ ìŠ¤í”Œë¦¿ ì‹œë“œë¥¼ ë§Œë“¤ì–´ [1, 10]ë¡œ ì§„í–‰ ì˜ˆì •\n",
    "iterations = [1, 10] \n",
    "\n",
    "# 'Crown Detection'ëŠ” ì˜ˆì œ ë°ì´í„°ì…‹, ë°ëª¨ ë° í‰ê°€ì‹œì—ëŠ” 'CV_Competition'\n",
    "Dataset_Name = 'Crown Detection' \n",
    "\n",
    "# ê²°ê³¼ë¥¼ ëª¨ì•„ í•˜ë‚˜ì˜ csv íŒŒì¼ì— ì €ì¥\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Experiment Time', 'Iteration', 'Submission Function', \n",
    "    'IoU', 'Dice', 'Precision', 'Recall', 'Output Json Path',\n",
    "])\n",
    "csv_filename = f\"Evaluation_Results_{datetime.now().strftime('%y%m%d_%H%M%S')}.csv\"\n",
    "\n",
    "# ì„œë¡œ ë‹¤ë¥¸ iteration, submission functionìœ¼ë¡œ ì‹¤í—˜ ì§„í–‰\n",
    "for iteration in range(iterations[0], iterations[1] + 1):\n",
    "    yaml_path = f'Datasets/{Dataset_Name}/data_iter_{iteration:02d}.yaml'\n",
    "    for submission_function in submission_functions:\n",
    "        ex_time = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "        output_json_path = f\"{ex_time}_{submission_function}_Iter_{iteration}_detection_results.json\"\n",
    "        globals()[submission_function](yaml_path, output_json_path)\n",
    "        labels_dir = f\"Datasets/{Dataset_Name}/labels\"  \n",
    "        vis_output_dir = f\"{ex_time}_visualization_results\"  \n",
    "        image_level_result_path =f\"{ex_time}_{submission_function}_Iter_{iteration}_image_level_results.json\"\n",
    "        stats = eval_and_vis(yaml_path, output_json_path, labels_dir, image_level_result_path, vis_output_dir, vis=False) # ë¶„ì„ ë°©í–¥ì— ë”°ë¼ vis=True ì„¤ì •\n",
    "        new_row = {\n",
    "            'Experiment Time': ex_time,\n",
    "            'Iteration': iteration,\n",
    "            'Submission Function': submission_function,\n",
    "            'IoU': stats['IoU']['avg'],\n",
    "            'Dice': stats['Dice']['avg'],\n",
    "            'Precision': stats['Precision']['avg'],\n",
    "            'Recall': stats['Recall']['avg'],\n",
    "            'Output Json Pa th': output_json_path,\n",
    "        }\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        results_df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42711cc-d6dc-49db-b7cd-d9ebc4a9f596",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Evaluation_Results_250423_104555.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m decimal_places \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     14\u001b[0m transpose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmake_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_measures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_fmt_template\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignificance_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecimal_places\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023user\\Downloads\\CV_midterm_competition_code_v2\\competition_utils.py:438\u001b[0m, in \u001b[0;36mmake_tables\u001b[1;34m(input_csv_path, keep_columns, keep_measures, reduction, row, column, null_column, custom_fmt_template, significance_levels, decimal_places, transpose)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_tables\u001b[39m(input_csv_path, keep_columns, keep_measures, reduction, row, column, null_column, custom_fmt_template,\n\u001b[0;32m    435\u001b[0m                 significance_levels,decimal_places, transpose\n\u001b[0;32m    436\u001b[0m                ):\n\u001b[1;32m--> 438\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_measures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMeasure Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    439\u001b[0m     rename_row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df[row]\u001b[38;5;241m.\u001b[39munique(), df[row]\u001b[38;5;241m.\u001b[39munique()))\n\u001b[0;32m    440\u001b[0m     rename_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(df[column]\u001b[38;5;241m.\u001b[39munique(), df[column]\u001b[38;5;241m.\u001b[39munique()))\n",
      "File \u001b[1;32mc:\\Users\\2023user\\Downloads\\CV_midterm_competition_code_v2\\competition_utils.py:258\u001b[0m, in \u001b[0;36mreshape_df\u001b[1;34m(input_csv_path, keep_columns, column_groups, groups_name, value_name)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreshape_df\u001b[39m(input_csv_path, keep_columns, column_groups, groups_name, value_name):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# Load CSV file\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_csv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcp949\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Drop rows with missing values in specified columns\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39mkeep_columns \u001b[38;5;241m+\u001b[39m column_groups)\n",
      "File \u001b[1;32mc:\\Users\\2023user\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023user\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\2023user\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\2023user\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\2023user\\anaconda3\\envs\\ComputerVision\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Evaluation_Results_250423_104555.csv'"
     ]
    }
   ],
   "source": [
    "# ë¶„ì„ ë°©í–¥ì— ë”°ë¼ ì „ì²´ ê²°ê³¼ë¥¼ ëª¨ì•„ í‰ê· -í‘œì¤€í¸ì°¨-í†µê³„í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ \n",
    "\n",
    "keep_columns = ['Iteration','Submission Function']\n",
    "keep_measures = ['IoU','Dice','Precision','Recall']  \n",
    "\n",
    "reduction = 'Iteration'\n",
    "row = 'Measure Type'\n",
    "column = 'Submission Function'\n",
    "reference_column = 'submission_1_20214173'  # í†µê³„ í…ŒìŠ¤íŠ¸ ê¸°ì¤€ì´ ë˜ëŠ” submission function\n",
    "\n",
    "custom_fmt_template = '{mean_fmt} Â± {std_fmt} {significance}'\n",
    "significance_levels = [0.1, 0.05, 0.01]\n",
    "decimal_places = 3\n",
    "transpose = True\n",
    "make_tables(csv_filename, keep_columns, keep_measures, reduction, row, column,  \n",
    "            reference_column, custom_fmt_template, significance_levels, decimal_places, transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f0a89-b0b6-4406-9500-24156dabcfc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
